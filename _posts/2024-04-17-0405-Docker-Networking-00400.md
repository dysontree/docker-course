---
layout: article
---

Итак, на рисунке три контейнера исполняются в сети по умолчанию, т.е. в сети `bridge`. Контейнер #1 (который с IP 172.17.0.2) имеет в себе flask-приложение, и его веб-сервер настроен на TCP-порту `5000`. Также ему необходимо быть доступным из внешней сети по порту хоста `41232`. 

В случае обращения по адресу `10.0.0.13:41232` (т.е. по внешнему адресу хоста) запрос передается процессу `docker-proxy`, который знает, что должен передать этот запрос контейнеру. Именно он пересылает его на правильный адрес и порт контейнера в частной сети хоста. Обратный трафик от запроса проходит через тот же маршрут.

Исходящий трафик из контейнера движется совершенно иначе, в нём docker-proxy вообще не задействован. Скажем, контейнер #3 хочет обратиться к серверу во внешней сети. У контейнера есть только его приватный адрес 172.17.0.4, а его маршрут по умолчанию — интерфейс `docker0`. Поэтому он отправляет трафик на 172.17.0.1. Шлюз получает пакеты и видит, что этот трафик исходящий, и что включена переадресация трафика. Поскольку сеть Docker является частной, пакеты не смогут вернуться на него из публичной сети. Поэтому перед отсылкой потребуется поменять адрес отправителя на внешний адрес хоста, а далее, при получении сопоставить эту замену, и отправить пакет во внутреннюю сеть. 

В ядре есть механизм, умеющий делать. Он называется трансляцией сетевых адресов или `NAT`. Таким образом, трафик выходит через `eth0` нашего хоста и имеет обратный адрес как `10.0.0.13`. Именно по нему придёт обратный трафик, будет обработан ядром и передан в частную сеть.

Как видишь, абстракция сетей отлично скрывает от нас эту сложность реализации. Но на деле это ещё немного сложнее, поскольку каждый контейнер исполняется в собственной отдельной песочнице - сетевом пространстве имён. Исполняясь в них, они не имеют доступа к реальным сетевым интерфейсам хоста, они не могут дотянуться до эффективных правил iptables и т.д.
