---
layout: article
---

Как я сказал, это не повседневная техника. Второй вариант - это полностью отделённый от хостового новый демон Docker, который исполняется в контейнере хостового Docker. Тут удобство в том, что всё, что происходит в контейнерах второго Docker там и остаётся.

Для запуска потребуется привилегированный режим.

```
docker run --privileged -d --name dind docker:dind
```

На хосте у нас один исполняемый контейнер.

```
docker container ls
```

Скачаю образ во внутренний Docker.

```
docker container exec -it dind docker pull ubuntu
```

Как видишь, внутри всего один образ с ubuntu. Хотя там должен быть образ docker:dind, контейнер который мы только что запустили на хосте.

```
docker container exec -it dind docker image ls
```

Надеюсь я убедил тебя, это два разных Dockers, не связанных между собой.

Это часто требуется для целей сборок в CI/СD. Лично мне первый раз это понадобилось еще в 2019 для сборки и отправки образов в Gitlab внутри docker-executor. В то время запуск DinD в пайплайне занял у меня что-то около трёх суток. Теперь Gitlab не рекомендует такой подход, но он всё еще возможен. В данный момент я стараюсь использовать `kaniko` в качестве альтернативы.

Отметь, что для учёбных целей можно запустить swarm-кластер с менеджером на хосте и воркерами в dind-контейнерах. Рабочей пользы от него не будет, но для обучения подойдёт.

Здесь мы запускали `dind` в стандартном райнтайме `runc`. Также можно использовать кастомные рантаймы, вроде `kata containers` или `sysbox` для запуска контейнеров в микровиртуальных машинах. Эти технологии лучше изолируют процессы от хоста, и мы можем просто инсталлировать Docker в контейнер после запуска. Это будет гораздо безопаснее, хотя скажется на производительности.

И это всё. Увидимся!
